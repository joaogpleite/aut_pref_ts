# -*- coding: utf-8 -*-
"""Automacao_Pref_TS_Versao_final_.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ofJzwsl8K03zVCi3Wx5XiuuAe7T8446D

## Pré-requisitos da plataforma
### Google Colab, Chromium e Selenium

O código utiliza o Selenium e o Chromium para **automatizar cliques em páginas e aplicações web**. 

Anteriormente, o Google Colab já tinha as configurações e drivers necessários para rodar o Chromium, mas agora é preciso **instalar o Chromium através de uma distribuição do Debian*** para continuar com a automação. 

Abaixo está o **passo a passo** para realizar a instalação
"""

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# # Ubuntu no longer distributes chromium-browser outside of snap
# #
# # Proposed solution: https://askubuntu.com/questions/1204571/how-to-install-chromium-without-snap
# 
# # Add debian buster
# cat > /etc/apt/sources.list.d/debian.list <<'EOF'
# deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster.gpg] http://deb.debian.org/debian buster main
# deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster-updates.gpg] http://deb.debian.org/debian buster-updates main
# deb [arch=amd64 signed-by=/usr/share/keyrings/debian-security-buster.gpg] http://deb.debian.org/debian-security buster/updates main
# EOF
# 
# # Add keys
# apt-key adv --keyserver keyserver.ubuntu.com --recv-keys DCC9EFBF77E11517
# apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 648ACFD622F3D138
# apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 112695A0E562B32A
# 
# apt-key export 77E11517 | gpg --dearmour -o /usr/share/keyrings/debian-buster.gpg
# apt-key export 22F3D138 | gpg --dearmour -o /usr/share/keyrings/debian-buster-updates.gpg
# apt-key export E562B32A | gpg --dearmour -o /usr/share/keyrings/debian-security-buster.gpg
# 
# # Prefer debian repo for chromium* packages only
# # Note the double-blank lines between entries
# cat > /etc/apt/preferences.d/chromium.pref << 'EOF'
# Package: *
# Pin: release a=eoan
# Pin-Priority: 500
# 
# 
# Package: *
# Pin: origin "deb.debian.org"
# Pin-Priority: 300
# 
# 
# Package: chromium*
# Pin: origin "deb.debian.org"
# Pin-Priority: 700
# EOF

"""## Instalação das bibliotecas necessárias

### Update, Chromium e Selenium

Estamos instalando as **bibliotecas necessárias para o código de scraping**, que será utilizado. 

A inclusão da **linha de código abaixo é importante** para garantir que todas as dependências estejam atualizadas e o código seja executado **corretamente**:

```
!apt-get update
```

"""

# Commented out IPython magic to ensure Python compatibility.
# %time
# Instalação de bibliotecas
!apt-get update
!apt-get install chromium chromium-driver
!pip3 install selenium

"""## Importação das bibliotecas necessárias

Aqui é feita a importação das bibliotecas que serão utilizadas para realizar, de fato, a raspagem de dados no site da Prefeitura de Taboão da Serra (SP).
"""

# Importação de bibliotecas
import time
import pandas as pd
import gspread
import getpass 
import requests

from oauth2client.service_account import ServiceAccountCredentials
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By

"""## Aquivo JSON e Credenciais

Como parte da automação trabalhará com ferramentas do Google G-Suit, é necessário validar seu acesso junto à API da plataforma. 
"""

nome_json = '/content/insperautomacao-joao-2f50fd8a490f.json'
conta = ServiceAccountCredentials.from_json_keyfile_name(nome_json)
token = getpass.getpass()

"""## Google Spreadsheet

A solução escolhida foi o Google Sheets por sua capacidade de automação e integração com outras ferramentas, o que aumenta as oportunidades de aplicação. 

Com o Google Sheets é possível automatizar processos e integrar dados de várias fontes em um só lugar.
"""

api = gspread.authorize(conta) # sheets.new
planilha = api.open_by_key("1bmLZIrWU1GG_ikJKRcZNtmmFELcYrBK2dMYqFQIV0Gs")
sheet = planilha.worksheet("lic1")

"""## Link do site da Prefeitura de Taboão da Serra (Sp)"""

# URL da página a ser acessada
url = "https://leideacesso.etransparencia.com.br/taboaodaserra.prefeitura.sp/TDAPortalClient.aspx?417"

"""## Configurações do navegador para poder acessar"""

# Opções do navegador
options = Options()
options.add_argument("--headless")
options.add_argument("--no-sandbox")

# Inicialização do driver
driver = webdriver.Chrome("chromedriver", options=options)

"""## Trabalhando os primeiros números

Esse trecho de código automatiza a navegação em uma página web específica usando o Selenium WebDriver. 

Ele clica em um botão da página, espera para que ela carregue, e extrai o conteúdo de uma tabela usando o método "pd.read_html". 

Em seguida, clica em outro botão, aguarda novamente, e extrai o conteúdo de outra tabela. O conteúdo de cada tabela é armazenado em listas separadas, "lista" e "lista_licitacoes1".
"""

driver.refresh()

# Navegação para a página
driver.get(url)

# Espera para carregar a página
time.sleep(4)

# Clique no botão desejado
botao = '/html/body/form/div[2]/div[2]/div[1]/div/div[2]/div/section/div/div/div/div/div[3]/div[2]/div/div/div/div[3]/div/table/tbody/tr[3]/td[5]/div/div[1]'
time.sleep(2)
driver.find_element(By.XPATH, botao).click()

# Espera para carregar a página
time.sleep(5)

# Obtenção do conteúdo da tabela
get_url = driver.find_element(By.XPATH, '/html/body/form/div[2]/div[2]/div[1]/div/div[2]/div/section/div[2]/div[1]/div/div/div[3]/div[1]/div[3]/div[2]/div/div/div/div[3]')
conteudo_tabela = get_url.get_attribute("outerHTML")
lista = pd.read_html(conteudo_tabela, thousands=',')

# Clique no próximo botão
botao2 = '/html/body/form/div[2]/div[2]/div[1]/div/div[2]/div/section/div[2]/div[1]/div/div/div[3]/div[1]/div[3]/div[2]/div/div/div/div[3]/div/table/tbody/tr[3]/td[2]/a'
driver.find_element(By.XPATH, botao2).click()

# Espera para carregar a página
time.sleep(4)

# Obtenção do conteúdo da segunda tabela
get_url1= driver.find_element(By.XPATH, '/html/body/form/div[2]/div[2]/div[1]/div/div[2]/div/section/div[2]/div[1]/div/div/div[3]/div[3]/div[3]/div[2]/div/div/div/div[3]/div/table')
conteudo_tabela1 = get_url1.get_attribute("outerHTML")
lista_licitacoes1 = pd.read_html(conteudo_tabela1, thousands=',')

# Espera para carregar a página
time.sleep(2)

# Obtenção do conteúdo da terceira tabela
get_url2= driver.find_element(By.XPATH, '/html/body/form/div[2]/div[2]/div[1]/div/div[2]/div/section/div[2]/div[1]/div/div/div[3]/div[3]/div[1]/div[2]/div/div/div/div[3]/div/table')
conteudo_tabela2 = get_url2.get_attribute("outerHTML")
lista_licitacoes2 = pd.read_html(conteudo_tabela2, thousands=',')

"""### Tratamento dos dados para pré configuração de banco de dados final.

Além de raspar os dados, também era preciso entender de que maneira os dados seriam montados e exposto no dataframe final. 

Para isso, foi necessário, organizar uma pequena amostra dos dados coletados a fim de que se pudesse ter uma ideia do formato final.

## Estratégia

O código está fazendo tratamento dos dados, aplicando transformações em duas DataFrames diferentes (df1 e df2) que foram extraídas anteriormente de tabelas do site. 

Em df1, o código está renomeando as colunas, convertendo os tipos de dados de algumas colunas e substituindo valores específicos em algumas colunas. 

Já Em df2, o código está renomeando as colunas, convertendo os tipos de dados de algumas colunas e realizando transformações em algumas colunas específicas. 

O objetivo é limpar e estruturar os dados para serem usados posteriormente na análise.
"""

# Tratamento dos dados
df1 = pd.DataFrame(lista[0])
df1.columns = df1.iloc[0]
df1.drop(1, inplace=True)
df1['Modalidade'] = df1['Modalidade'].astype(str)
df1['Número/Processo'] = df1['Número/Processo'].astype(str)
df1['Situação'] = df1['Situação'].astype(str)
df1['Total registro de preço'] = df1['Total registro de preço'].astype(str)
df1['Valor estimado'] = df1['Valor estimado'].str.replace('\.', '', regex=True).str.replace(',', '.', regex=False)
df1['Valor estimado'] = df1['Valor estimado'].replace('000', '0')
df1['Valor comprado'] = df1['Valor comprado'].str.replace('\.', '', regex=True).str.replace(',', '.', regex=False)
df1['Valor comprado'] = df1['Valor estimado'].replace('000', '0')
df1 = df1.reset_index(drop=True)


df2 = pd.DataFrame(lista_licitacoes1[0])
df2.columns = df2.iloc[0]
df2 = df2.drop(0)
df2['Qtd Solicitada'] = df2['Qtd Solicitada'].str.replace(',', '.').replace('\.', '', regex=True).astype(float) / 100
df2['Valor Unitário'] = df2['Valor Unitário'].str.replace('\.', '', regex=True).str.replace(',', '.', regex=False).astype(float)
df2['Valor Total'] = df2['Valor Total'].str.replace('\.', '', regex=True).str.replace(',', '.', regex=False).astype(float)
df2['Descrição'] = df2['Descrição'].astype(str)
df2['Unidade'] = df2['Unidade'].astype(str)
df2['Vencedor'] = df2['Vencedor'].astype(str)
df2 = df2.reset_index(drop=True)

df3 = pd.DataFrame(lista_licitacoes2[0])
df3.columns = df3.iloc[0]
df3 = df3.drop(0)
df3['Órgão'] = df3['Órgão'].astype(str)
df3['Unidade Orçamentária'] = df3['Unidade Orçamentária'].astype(str)
df3['Quantidade Total'] = df3['Quantidade Total'].astype(int)
df3 = df3.reset_index(drop=True)

df1.head()

df2.head()

df3.columns

"""## Função de classificação das Secretarias da Prefeitura de Taboão da Serra (SP)

Foi identificada a ausência de um dado importante para a análise de erros: a secretaria que solicitou a demanda licitada. 

Para resolver esse problema, foi criada uma **função que busca um dicionário de siglas** e cria uma **nova coluna** com o nome completo da secretaria correspondente. 

Esse dicionário foi encontrado através da análise dos endereços de e-mail das secretarias, que seguiam um padrão identificável [no próprio site da prefeitura de Taboão da Serra (SP)](https://prefeitura.ts.sp.gov.br/secretarias/)
"""

df_final = pd.read_csv('/content/df_finalV2.csv', index_col=[0])

def adiciona_secretaria(df_teste, dici):
    secretarias = []
    for descricao in df_teste["Finalidade/Objeto/Serviço"]:
        for chave, valor in dici.items():
            if chave.lower() in descricao.lower():  # Busca a sigla em minúsculas
                secretarias.append(valor)
                break
        else:
            secretarias.append(None)
    df_teste["Secretaria"] = secretarias
    return df_teste

dici = {"Sma" : "Secretaria Municipal de Administração e Tecnologia",
        "Sas": "Secretaria Municipal de Assistência Social e Cidadania",
        "Sj" : "Secretaria Municipal de Assuntos Jurídicos",
        "Secom": "Secretaria Municipal de Comunicação",
        "Sec": "Secretaria Municipal de Cultura e Turismo",
        "Sde": "Secretaria Municipal de Desenvolvimento Econômico e Trabalho",
        "Sehab": "Secretaria Municipal de Desenvolvimento Urbano, Habitação e Meio Ambiente",
        "Seduc": "Secretaria Municipal de Educação",
        "educacional":"Secretaria Municipal de Educação",
        "Emef":"Secretaria Municipal de Educação",
        "Semel": "Secretaria Municipal de Esportes e Lazer",
        "Sefaz" : "Secretaria Municipal de Finanças e Planejamento",
        "Sgp": "Secretaria Municipal de Gestão de Pessoas",
        "Semugov": "Secretaria Municipal de Governo",
        "Sema": "Secretaria Municipal de Serviços Urbanos e Manutenção",
        "Smo": "Secretaria Municipal de Obras e Infraestrutura",
        "construcao": "Secretaria Municipal de Obras e Infraestrutura",
        "contrucao": "Secretaria Municipal de Obras e Infraestrutura",
        "Seplan": "Secretaria Municipal de Gestão Estratégica",
        "Sms": "Secretaria Municipal de Saúde",
        "bomba Infusao" : "Secretaria Municipal de Saúde",
        "ubs": "Secretaria Municipal de Saúde",
        "emergencial":"Secretaria Municipal de Saúde",
        "medicamento" : "Secretaria Municipal de Saúde",
        "Sds": "Secretaria Municipal de Segurança e Defesa Social",
        "municao":"Secretaria Municipal de Segurança e Defesa Social",
        "Setram": "Secretaria Municipal de Transportes e Mobilidade Urbana",
        "" : "Secretaria não especificada"}

"""## Função de classificação do tipo de Ação promovida pelas Secretarias da Prefeitura de Taboão da Serra (SP)

Outro dado que faltava ao banco de dados era uma coluna específica para o tipo de ação que a prefeitura estaria promovendo. 

Dessa forma, a abordagem também foi a da criação de uma função com a acima, que **busca um dicionário de palavras** manualmente identificadas e cria uma **nova coluna** com o nome completo da ação correspondente. 

Esse dicionário foi encontrado através da análise das descrições e documentos abertos [no próprio site da prefeitura de Taboão da Serra (SP)](https://prefeitura.ts.sp.gov.br/secretarias/)
"""

def adiciona_tipo_despesa(df_teste, dici):
    despesa = []
    for descricao in df_teste["Descrição"]:
        for chave, valor in dici.items():
            if chave.lower() in descricao.lower():  # Busca a sigla em minúsculas
                despesa.append(valor)
                break
        else:
            despesa.append(None)
    df_teste["Tipo de Despesa"] = despesa
    return df_teste

tipo = {"aq" : "Aquisição",
        "aquisicao": "Aquisição",
        "asquisicao" : "Aquisição",
        "capacitacao":"Capacitação",
        "cont": "Contratação",
        "contratacao": "Contratação",
        "contrat": "Contratação",
        "construcao": "Construção",
        "contrucao": "Contratação",
        "despesa": "Despesa",
        "despesas" : "Despesa",
        "implan" : "Implantação",
        "implant" : "Implantação",
        "implanta" : "Implantação",
        "prestacao": "Serviço",
        "pavimentacao":"Pavimentação",
        "reforma": "Reforma",
        "reform": "Reforma",
        "servico": "Serviço",
        "serv": "Serviço",
        "serv": "Serviço",
        "locacao":"Locação",
        "assinatura": "Assinatura",
        "consultoria": "Consultoria",
        "consult" : "Consultoria",
        "manutencao":"Manutenção",
        "manut":"Manutenção",
        "manut":"Manutenção",}

"""# Raspador de dados

Uma vez que o site da Prefeitura **não é um site que tem alteração de domínio** a cada nova função acessada, mas uma plataforma que responde a comandos.

A aplicação que permite o acesso às informações das licitações estão em um botão único em um dashboard. Já as informações específicas, precisavam ser acessadas por meio de um link no próprio número do processo dentro da tabela principal. 

Dessa forma, foi necessário adotar uma abordagem que considerasse:

- Escopo de tempo das licitações (2023)
- Onde clicar;
- Se o botão também não era um valor importante;
- O tempo para carregamento da segunda tabela;

### Estratégia
Assim, a estratégia abordada foi a seguinte:

1. O código começa criando um dicionário que relaciona as abreviações das secretarias municipais aos seus respectivos nomes completos. 

2. Em seguida, ele acessa um site específico utilizando o Selenium WebDriver, iterando em um range que o permite clicar nos links e extrair as tabelas. 

3. Cada tabela extraída é transformada em um DataFrame, com uma nova coluna contendo o número do processo licitatório. 

4. Todos os DataFrames são adicionados a uma lista que é concatenada em um único DataFrame, com as colunas renomeadas. 

5. Depois disso, é feito um merge desse DataFrame com outro que contém informações adicionais sobre os processos licitatórios. Algumas colunas são selecionadas e convertidas para formatos mais apropriados. 

6. Por fim, é criado um novo DataFrame adicionando uma coluna que indica a secretaria municipal correspondente a cada processo, com base no dicionário criado anteriormente. O resultado é um DataFrame final que é exibido na tela.
"""

# Commented out IPython magic to ensure Python compatibility.
#Raspador Original
# %time
df_list = []
df_sec = []

for i in range (0, 244):
    
    # clica no link correspondente à tabela desejada
    link_xpath = f'/html/body/form/div[2]/div[2]/div[1]/div/div[2]/div/section/div[2]/div[1]/div/div/div[3]/div[1]/div[3]/div[2]/div/div/div/div[3]/div/table/tbody/tr[{3+i}]/td[2]/a'
    time.sleep(4)
    driver.find_element(By.XPATH, link_xpath).click()
    
    # espera 4 segundos para a tabela carregar
    time.sleep(4)
    
    # extrai o conteúdo da tabela
    tabela_xpath = '/html/body/form/div[2]/div[2]/div[1]/div/div[2]/div/section/div[2]/div[1]/div/div/div[3]/div[3]/div[3]/div[2]/div/div/div/div[3]/div/table'
    tabela_element = driver.find_element(By.XPATH, tabela_xpath)
    tabela_html = tabela_element.get_attribute("outerHTML")
    
    # converte a tabela em DataFrame
    tabela_df = pd.read_html(tabela_html, decimal=',', thousands='.')[0]

    # Cria uma nova coluna em tabela_df chamada 'Número/Processo'
    tabela_df['Número/Processo'] = df1['Número/Processo'].iloc[i+1]
    tabela_df['Modalidade'] = df1['Modalidade'].iloc[i+1]
    tabela_df['Situação'] = df1['Situação'].iloc[i+1]
    tabela_df.drop(0, inplace=True)
    
    # adiciona o DataFrame à lista
    df_list.append(tabela_df)
    
    
# concatena todos os DataFrames em um único DataFrame
dflicitacoes = pd.concat(df_list)
dflicitacoes.columns = ["Descrição", "Unidade", "Qtd Solicitada", "Valor Unitário", "Valor Total", "Vencedor", "Número/Processo", 'Modalidade', 'Situação']

#Faz o merge com o df1 para gerar o df_lic_final
dfs_merge = pd.merge(df1, dflicitacoes, on=['Número/Processo', 'Modalidade', 'Situação'])
dfs_merge.columns

#Limpeza e reestruturação de dados para o formato mais conveniente
df_qfinal = dfs_merge[['Número/Processo', 'Modalidade', 'Situação', 'Data', 'Finalidade/Objeto/Serviço', 'Descrição', 'Vencedor', 'Qtd Solicitada', 'Unidade', 'Valor Unitário', 'Valor Total', 'Total registro de preço', 'Valor comprado', 'Valor estimado']]


## Conversões para Float64
df_qfinal['Qtd Solicitada'] = df_qfinal['Qtd Solicitada'].astype(float)
df_qfinal['Valor Unitário'] = df_qfinal['Valor Unitário'].astype(float)
df_qfinal['Valor Total'] = df_qfinal['Valor Total'].astype(float)
df_qfinal['Total registro de preço'] = df_qfinal['Total registro de preço'].replace('000', '0')
df_qfinal['Valor comprado'] = df_qfinal['Valor comprado'].astype(float)
df_qfinal['Valor estimado'] = df_qfinal['Valor estimado'].astype(float)

## Conversões para String
df_qfinal['Número/Processo'] = df_qfinal['Número/Processo'].astype(str)
df_qfinal['Finalidade/Objeto/Serviço'] = df_qfinal['Finalidade/Objeto/Serviço'].astype(str)
df_qfinal['Descrição'] = df_qfinal['Descrição'].astype(str)
df_qfinal['Vencedor'] = df_qfinal['Vencedor'].astype(str)
df_qfinal['Número/Processo'] = df_qfinal['Número/Processo'].astype(str)

# Utilizando a função para montar o df_final
df_final = adiciona_secretaria(df_qfinal, dici)
df_final = adiciona_tipo_despesa(df_final, tipo)
df_final[['Número/Processo', 'Secretaria', 'Modalidade', 'Situação', 'Data', 'Finalidade/Objeto/Serviço', 'Descrição', 'Vencedor', 'Qtd Solicitada', 'Unidade', 'Valor Unitário', 'Valor Total', 'Total registro de preço', 'Valor comprado', 'Valor estimado']]
print(df_final.columns)

"""# Confirmação dos dados do Data Frame final (df_final)


"""

df_final

"""## Envio do DataFrame para o Google Sheets

Uma vez com os dados organizados em um DataFrame, o próximo passo da função é transforma-lo em uma planilha no Google Sheets que será integrada ao Projeto Zheeta da disciplina de Algoritmos de Automação. 
"""

# Converter o dataframe em uma lista de dicionários para inserir na planilha
dados = df_final.to_dict(orient='records')

# Obter os nomes das colunas do dataframe
nomes_colunas = list(df_final.columns)

# Criar um dicionário com as chaves sendo os nomes das colunas e os valores sendo os mesmos nomes das colunas
cabecalho = {coluna: coluna for coluna in nomes_colunas}

# Adicionar o cabeçalho como o primeiro item na lista de dados
dados.insert(0, cabecalho)

# Definir o intervalo de células que deseja atualizar com os dados
intervalo_celulas = f'A1:{chr(ord("A") + len(df_final.columns) - 1)}{len(df_final.index) + 1}'

# Atualizar as células na planilha com os dados do dataframe
sheet.clear()
sheet.update(intervalo_celulas, [list(d.values()) for d in dados])

"""# Análise Exploratória de Dados"""

df_final.columns

"""## Valores"""

df_final['Valor Total'].describe().apply(lambda x: format(round(x, 2), '.2f'))

"""## Modalidades"""

df_final['Modalidade'].value_counts()

"""## Tipos de Despesa"""

df_final['Tipo de Despesa'].value_counts()

"""## Situação"""

df_final['Situação'].value_counts()

"""## Vencedor"""

df_final['Vencedor'].value_counts()

"""## Secretarias

# Qual secretaria lidera em número de compras?
"""

df_final['Secretaria'].value_counts()

import plotly.express as px
import plotly.graph_objects as go

df5 = df_final.groupby('Vencedor').size().reset_index(name='count').sort_values('count', ascending=False)
fig5 = px.bar(df5.head(20), x='Vencedor', y='count', title='Quantas vezes cada Vencedor ganhou uma licitação')
fig5.show()

"""# Lixo"""

def adiciona_secretaria2(df_teste, dici):
    secretarias = []
    for descricao in df_teste["Finalidade/Objeto/Serviço"]:
        for chave, valor in dici.items():
            if chave.lower() in descricao.lower():  # Busca a sigla em minúsculas
                secretarias.append(valor)
                break
        else:
            secretarias.append(None)
    df_teste["Secretaria"] = secretarias
    return df_teste

def obter_nome_secretaria(sigla):
    sigla = sigla.lower()  # Converter a sigla para letras minúsculas
    return dici.get(sigla, "Secretaria não encontrada")  # Buscar a sigla no dicionário

"""# Texto"""

media_idade = df_final['Valor Total'].mean()

print(f"A média de valor das licitações é de {media_idade:.2f} Reais.")

licitacao_mais_comum = df_final['Modalidade'].mode()[0]
print(licitacao_mais_comum)

convites = df_final[df_final['Modalidade'] == 'Convite']
secretaria_mais_convites = convites['Secretaria'].value_counts().index[0]
maior_convite_secretaria = convites[convites['Secretaria'] == secretaria_mais_convites]['Valor Total'].max()

print(secretaria_mais_convites)
print(maior_convite_secretaria)

media_valor = df_final['Valor Total'].mean()
print(media_valor)

maior_valor_licitacao = df_final.loc[df_final['Valor Total'].idxmax()]
print(maior_valor_licitacao)

menor_valor_licitacao = df_final.loc[df_final['Valor Total'].idxmin()]
print(menor_valor_licitacao)

licitacoes_encerradas = df_final[df_final['Situação'] == 'encerrada']
total_encerradas = len(licitacoes_encerradas)
print(total_encerradas)

licitacoes_encerradas = df_final[df_final['Situação'] == 'encerrada']
media_valor_encerradas = licitacoes_encerradas['Valor Total'].mean()
print(media_valor_encerradas)

licitacao_maior_valor_estimado = df_final.loc[df_final['Valor estimado'].idxmax()]
print(licitacao_maior_valor_estimado)

licitacoes_2023 = df_final[df_final['Data'].str.contains('2023')]
secretaria_mais_licitacoes_2023 = licitacoes_2023['Secretaria'].value_counts().index[0]
print(secretaria_mais_licitacoes_2023)

# Agrupando por vencedor e somando os valores totais
maiores_vencedores = df_final.groupby('Vencedor')['Valor Total'].sum().sort_values(ascending=False)

# Selecionando os maiores vencedores
maior_vencedor = maiores_vencedores.index[0]

# Filtrando as licitações do maior vencedor
licitacoes_maior_vencedor = df_final[df_final['Vencedor'] == maior_vencedor]

# Agrupando as modalidades das licitações do maior vencedor
modalidades_maior_vencedor = licitacoes_maior_vencedor.groupby('Modalidade')['Valor Total'].sum().sort_values(ascending=False)

# Agrupando as secretarias das licitações do maior vencedor
secretarias_maior_vencedor = licitacoes_maior_vencedor.groupby('Secretaria')['Valor Total'].sum().sort_values(ascending=False)

# Imprimindo os resultados
print(f'O maior vencedor das licitações foi {maior_vencedor}.')
print(f'As modalidades em que esse vencedor mais ganhou foram:')
for modalidade, valor in modalidades_maior_vencedor.iteritems():
    print(f'{modalidade}: {valor}')
print(f'As secretarias em que esse vencedor mais ganhou foram:')
for secretaria, valor in secretarias_maior_vencedor.iteritems():
    print(f'{secretaria}: {valor}')

import altair as alt

bars = alt.Chart(df_final).mark_bar().encode(
    y=alt.Y('Vencedor:N', sort='-x'),
    x='Valor Total:Q',
    tooltip=['Vencedor', 'Valor Total']
)

bars

import altair as alt

bars = alt.Chart(licitacoes_maior_vencedor).mark_bar().encode(
    y=alt.Y('Modalidade:N', sort='-x'),
    x='Valor Total:Q',
    tooltip=['Modalidade', 'Valor Total']
)

bars

import altair as alt

bars = alt.Chart(licitacoes_maior_vencedor).mark_bar().encode(
    y=alt.Y('Secretaria:N', sort='-x'),
    x='Valor Total:Q',
    tooltip=['Secretaria', 'Valor Total']
)

bars



alt.Chart(df_final, title = alt.TitleParams(
    text = 'Posicionamento dos partidos por ano',
    subtitle= ['Mudança no posicionamento do partido', 'entre o ano de 2019 e 2021'],
    fontSize = 30,
    font = 'Acumin Pro Wide',
    anchor = 'start',
    offset=20
)).mark_point(filled=True).encode(
    x="deputado_siglaPartido",
    y="perc_gov",
    color = alt.Color('Cluster', scale=alt.Scale(domain=["0", "1", "2"], range=['#00ff1e', '#ff0000', '#1f00ff'])).title("Classificação do deputado"),
    size = alt.Size("total_votos", scale=alt.Scale(range=[20, 100])).title("Total de votos"),
    tooltip = ["perc_gov", 'deputado_siglaPartido', 'deputado_nome', "total_votos"],
    shape = alt.Shape('ano').title("Ano")
).configure_axis(
    labelFont='Acumin Pro SemiCondensed'
).configure_mark(opacity=0.5).properties(width=500, height=500)

"""Quanto """